What is Web Scrapping?
Web scraping is an automated method used to extract large amounts of data from websites. The data on the websites are unstructured. Web scraping helps collect these unstructured data and store it in a structured form. There are different ways to scrape websites such as online Services, APIs or writing your own code. In this article, we’ll see how to implement web scraping with python. 

Imagine you have to pull a large amount of data from websites and you want to do it as quickly as possible. How would you do it without manually going to each website and getting the data? Well, “Web Scraping” is the answer. Web Scraping just makes this job easier and faster. 

How does it work?
Once the code is written and run, a request for scraping is sent to your website of choice. If the request is approved, the server will send the desired data, allowing you to read the HTML or XML page. The code then automatically analyses the HTML or XML page, finds and parses the desired data.

Some basic steps used for web scraping with Python:

Step 1: Choose the URL from which you would like to scrape

Step 2: Read the page and find the data you would like to collect

Step 3: Write the code

Step 4: Run the code to extract the data

Step 5: Store the data in the necessary format

Given below are some modules that makes it easier to scrap web pages in Python
webbrowser - Comes with python and opens a browser to a specific page
Requests - Downloads files and web pages from the internet
Beautiful soup - Parses HTML, the format that web pages are written in
Selenium - Launches and controls a web browser. Selenium is able to fill in forms and simulate mouse clicks in this browser

Project: mapit.py with the webbrowser Module

The webbrowser module’s open() function can launch a new browser to a specified URL.
Enter the following into the interactive shell:
>>> import webbrowser
>>> webbrowser.open('http://inventwithpython.com/')
A web browser tab will open to the URL http://inventwithpython.com/. This is about the only thing
the webbrowser module can do. Even so, the open() function does make some interesting things
possible. For example, it’s tedious to copy a street address to the clipboard and bring up a map of
it on Google Maps. You could take a few steps out of this task by writing a simple script to
automatically launch the map in your browser using the contents of your clipboard.

Step 1: Figure Out the URL
set up mapIt.py so that when you run it from the command line, like so...
C:\> mapit 870 Valencia St, San Francisco, CA 94110
The script will use the command line arguments instead of the clipboard. If there are no command
line arguments, then the program will know to use the contents of the clipboard.
First you need to figure out what URL to use for a given street address. When you load
http://maps.google.com/ in the browser and search for an address, the URL in the address bar looks
something like this:
https://www.google.com/maps/place/870+Valencia+St/@37.7590311,-122.4215096,17z/data

    Step 2: Handle the Command Line Arguments
Make your code look like this:
#! python3
# mapIt.py - Launches a map in the browser using an address from the
# command line or clipboard.
import webbrowser, sys
if len(sys.argv) > 1:   
# Get address from command line.
address = ' '.join(sys.argv[1:])
# TODO: Get address from clipboard.

Step 3: Handle the Clipboard Content and Launch the Browser
Make your code look like the following:
#! python3
# mapIt.py - Launches a map in the browser using an address from the
# command line or clipboard.
import webbrowser, sys, pyperclip
if len(sys.argv) > 1:
# Get address from command line.
address = ' '.join(sys.argv[1:])
else:
# Get address from clipboard.
address = pyperclip.paste()
webbrowser.open('https://www.google.com/maps/place/' + address)

If there are no command line arguments, the program will assume the address is stored on the
clipboard. You can get the clipboard content with pyperclip.paste() and store it in a variable named
address. Finally, to launch a web browser with the Google Maps URL, call webbrowser.open().
While some of the programs you write will perform huge tasks that save you hours, it can be just
as satisfying to use a program that conveniently saves you a few seconds each time you perform a
common task, such as getting a map of an address.

Parsing HTML with the BeautifulSoup Module

For the Beautiful Soup examples will parse an HTML file on the hard drive. Open a new file editor window in IDLE, enter the following, and save it as example.html. Alternatively, download it from http://nostarch.com/automatestuff/.
<!-- This is the example.html example file. -->
<html><head><title>The Website Title</title></head>
<body>
<p>Download my <strong>Python</strong> book from <a href="http://
inventwithpython.com">my website</a>.</p>
<p class="slogan">Learn Python the easy way!</p>
<p>By <span id="author">Al Sweigart</span></p>
</body></html>
As you can see, even a simple HTML file involves many different tags and attributes, and
matters quickly get confusing with complex websites. Thankfully, Beautiful Soup makes working
with HTML much easier.

The bs4.BeautifulSoup() function needs to be called with a string containing the HTML it will
parse. The bs4.BeautifulSoup() function returns is a BeautifulSoup object. Enter, the following
into the interactive shell while your computer is connected to the Internet:
>>> import requests, bs4
>>> res = requests.get('http://nostarch.com')
>>> res.raise_for_status()
>>> noStarchSoup = bs4.BeautifulSoup(res.text)
>>> type(noStarchSoup)
<class 'bs4.BeautifulSoup'>